{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146413d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset import *\n",
    "from spdnet.spd import SPDTransform, SPDTangentSpace, SPDRectified\n",
    "from spdnet.optimizer import StiefelMetaOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598c16cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/JJ/Desktop/fMRISPDCluster\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27204fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recurrent_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(recurrent_layer, self).__init__()\n",
    "        self.rect1  = SPDRectified()\n",
    "        #self.rect2  = SPDRectified()\n",
    "        #self.rect3  = SPDRectified()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rect1(x)\n",
    "        #x = self.rect2(x)\n",
    "        #x = self.rect3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b5667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(input_layer, self).__init__()\n",
    "        self.trans1 = SPDTransform(57, 20)\n",
    "        self.trans2 = SPDTransform(20, 10)\n",
    "        self.trans3 = SPDTransform(10, 2)\n",
    "        self.rect1  = SPDRectified()\n",
    "        self.rect2  = SPDRectified()\n",
    "        self.rect3  = SPDRectified()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.trans1(x)\n",
    "        x = self.rect1(x)\n",
    "        x = self.trans2(x)\n",
    "        x = self.rect2(x)\n",
    "        x = self.trans3(x)\n",
    "        x = self.rect3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84091643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class output_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(output_layer, self).__init__()\n",
    "        self.tangent = SPDTangentSpace(2)\n",
    "        self.linear = nn.Linear(3, 17, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tangent(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c22fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPDRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SPDRNN, self).__init__()\n",
    "        self.input_layer = input_layer()\n",
    "        self.output_layer = output_layer()\n",
    "        self.recurrent_layer = recurrent_layer()\n",
    "        self.alpha = .7\n",
    "\n",
    "    def forward(self, input, future=0):\n",
    "        outputs = []\n",
    "        # The two corresponds to the dimension of the recurrent SPD matrix.\n",
    "        h_t = torch.zeros(input.size(0), 2, 2, dtype=torch.float)\n",
    "        if use_cuda:\n",
    "            h_t = h_t.cuda()\n",
    "\n",
    "        for i in range(input.size(1)):\n",
    "            x = input[:, i, :, :]\n",
    "            tmp_a = self.alpha*self.input_layer(x)\n",
    "            tmp_b = (1-self.alpha)*self.recurrent_layer(h_t)\n",
    "            h_t = tmp_a + tmp_b\n",
    "            output = self.output_layer(h_t)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2488cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(x, ws=30):\n",
    "    d, n = x.shape\n",
    "    return np.stack([(1/n)*np.matmul(x[:, i:ws+i], x[:, i:ws+i].T) for i in range(n-ws)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60a2f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sliding_labels(x, ws=30):\n",
    "    n = x.shape[0]\n",
    "    return np.stack([x[int(ws/2)+i] for i in range(n-ws)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4821a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPDRNNDataset(Dataset):\n",
    "    def __init__(self, shuffle=False, scan_id=1, ws=30):\n",
    "        super(SPDRNNDataset, self).__init__()\n",
    "        self.scan_id = scan_id\n",
    "        self.ws = ws\n",
    "        lbls = np.loadtxt('./fMRIdata/timingLabels_WM_scan1.csv', dtype=np.int32)\n",
    "        data = []\n",
    "        labels = []\n",
    "        for i in range(1,31):\n",
    "            tmp_data = pd.read_csv(f'./fMRIdata/subject_1{i:02d}_scan{scan_id}.csv')\n",
    "            tmp_data = sliding_window(tmp_data.values, ws)\n",
    "            tmp_lbls = get_sliding_labels(lbls, ws)\n",
    "            data.append(tmp_data)\n",
    "            labels.append(tmp_lbls)\n",
    "        self.data = np.stack(data)\n",
    "        self.labels = np.stack(labels)[..., None] - 1.\n",
    "\n",
    "        if shuffle:\n",
    "            random.shuffle(self.data)\n",
    "\n",
    "        self.nSamples = len(self.data) \n",
    "        print(self.nSamples)\n",
    "        self.nClasses = 17\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nSamples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'data': torch.from_numpy(self.data[idx].astype(np.float32)), \n",
    "                'label': torch.from_numpy(self.labels[idx].astype(np.compat.long))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ecf2c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "transformed_dataset = SPDRNNDataset(scan_id=1, ws=30)\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "transformed_dataset_val = SPDRNNDataset(scan_id=2, ws=30)\n",
    "dataloader_val = DataLoader(transformed_dataset_val, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "use_cuda = False\n",
    "model = SPDRNN()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = StiefelMetaOptimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9884f58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    bar = tqdm(enumerate(dataloader))\n",
    "    for batch_idx, sample_batched in bar:\n",
    "        inputs = sample_batched['data']\n",
    "        targets = sample_batched['label'].squeeze()\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        targets = targets.view(-1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.data.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().data.item()\n",
    "\n",
    "        bar.set_description('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1.0), 100.*correct/total, correct, total))\n",
    "\n",
    "    return (train_loss/(batch_idx+1), 100.*correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5290d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    bar = tqdm(enumerate(dataloader_val))\n",
    "    for batch_idx, sample_batched in bar:\n",
    "        inputs = sample_batched['data']\n",
    "        targets = sample_batched['label'].squeeze()\n",
    "\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, outputs.shape[-1])\n",
    "        targets = targets.view(-1)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.data.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().data.item()\n",
    "\n",
    "        bar.set_description('Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model,\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/rnn_ckpt.t7')\n",
    "        best_acc = acc\n",
    "\n",
    "    return (test_loss/(batch_idx+1), 100.*correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba101cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = open('log_rnn.txt', 'a')\n",
    "\n",
    "start_epoch = 1\n",
    "for epoch in range(start_epoch, start_epoch+10):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    test_loss, test_acc = test(epoch)\n",
    "\n",
    "    log_file.write('%d,%f,%f,%f,%f\\n' % (epoch, train_loss, train_acc, test_loss, test_acc))\n",
    "    log_file.flush()\n",
    "\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4772426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
